<!DOCTYPE html>
<html>
  <head>
    <title>HarmonyLM</title> 
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="helper.js" defer></script>
    <style>
      td {
        vertical-align: middle;
      }
      audio {
        width: 20vw;
        min-width: 100px;
        max-width: 250px;
      }
    </style>
  </head>
  <body>
    <div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
      <div class="text-center">
        <h1>HarmonyLM</h1><h3>Unified Text-to-Sound And Text-to-Music Generation with discrete representations</h3>
        <p class="lead fw-bold">
          |<a
            href=""
            class="btn border-white bg-white fw-bold"
            >paper</a
          >|
        </p>
        <p class="fst-italic mb-0">
        Anonymous
        </p>
        <p><b></b></p>
      </div>
      <p>
        <b>Abstract.</b>  
        The fields of sound generation and music generation have seen notable advancements with the development of specialized models tailored to each domain. However, these domains share commonalities, and the use of specialized models can lead to increased hardware resource requirements. On the other hand, recent breakthroughs in large language models, particularly in natural language processing, have showcased their ability to capture complex patterns and generate coherent and contextually relevant outputs in various tasks. Leveraging the success of these language models, we present HarmonyLM, a unified framework designed to synthesize sound and music from discrete representations. HarmonyLM adopts a unified perspective in modeling sound and music, discrete tokens are modeled from text descriptions using a decoder-only model, which are converted back to harmonious and consistent audio outputs. HarmonyLM offers significant advantages as a unified sound and music generation framework. (1) Model Scalability: the model we use in acoustic modeling a decoder-only transformer, which is free to scale up model size. (2) Data Scalability: the acoustic modeling and reconstructing audio models do not require any annotations, which accommodate different scales of data. Experimental results demonstrate the effectiveness of HarmonyLM, as it achieves superior audio quality compared to competitive baseline models.
      </p>
    </div>

<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="model-overview" style="text-align: center;">HarmonyLM Overview</h2>
    <body>
    <p style="text-align: center;">
        <img src="model.png" height="200" width="800" class="img-fluid">
    </p>
    </body>
        <p>
          A high-level overview of HarmonyLM. We freeze the FLAN-T5 as our text encoder and use SoundStream as the audio tokenizer. The generated acoustic tokens by the autoregressive transformer are converted back to the raw sound/music with the unit-based vocoder.
        </p>
</div>
 
<div class="container pt-5 mt-5 shadow p-5 mb-5 bg-white rounded">
    <h2 id="model-overview" style="text-align: left;">Table of Contents</h2>
    <body>
    <p style="text-align: left;">
    <ul style="list-style: outside none none !important;">
       <li><a href="#efficiency" class="btn border-white bg-white fw-bold">Text-to-Sound Generation</a></li>
       <li><a href="#diversity" class="btn border-white bg-white fw-bold">Text-to-Music Generation</a></li>
       <!-- <li><a href="#prompting" class="btn border-white bg-white fw-bold">Impact of Architecture Scale</a></li> -->
    </ul>
    </p>
    </body>
</div>


    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Text-to-Sound Generation<a id="efficiency"/></h3>
      <!-- <p class="mb-0">
        We show the original natural language caption and the corresponding structured caption of Make-An-Audio 2. And we compare the audio generated by Make-An-Audio 2 to prior T2A works.
      </p> -->
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="supervision-efficiency-table">
          <thead>
            <tr>
              <th style="text-align: center" > &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspInput&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp</th>
              <th style="text-align: center">Ground-truth</th>
              <th style="text-align: center">HarmonyLM</th>
              <th style="text-align: center">Make-An-Audio 2</th>
              <th style="text-align: center">Audio-LDM</th>
              <th style="text-align: center">TANGO</th>
            </tr>
          </thead>
          <tbody>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr height=200px> <td></td> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
          </tbody>
        </table>
      </div>


    </div>



    <div class="container shadow p-5 mb-5 bg-white rounded">
      <h3>Text-to-Music Generation<a id="diversity"/></h3>
      <!-- <p class="mb-0">
      Trained with variable length data and with the design of 1D-convlution VAE and feed-forward Transformer-based diffusion backbone, Make-An-Audio 2 can generate audios of variable-length without performance dropping.
      </p> -->
      <div class="container pt-3 table-responsive">
        <table
          class="table table-hover"
          id="speech-diversity"
        >
          <thead>
            <tr>
              <th width="40%">&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspInput&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp</th>
              <th width="15%">Ground-truth</th>
              <th width="15%">HarmonyLM</th>
              <th width="15%">MusicGen</th>
              <th width="15%">MusicLM</th>
            </tr>
          </thead>
          <tbody>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
             <tr> <td></td> <td></td> <td></td> <td></td> <td></td> </tr>
          </tbody>
        </table>
      </div>
    </div>




  </body>
</html>